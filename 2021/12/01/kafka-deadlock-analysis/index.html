<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="Kafka死锁问题                           问题现象       以数据服务团队的CUPS系统为例，upkafka-1.0版本出现的问题主要会产生如下异常现象：  文件句柄增多（能够达到40w+） CLOSE_WAIT增多（数量同样非常巨大） 单节点hang住，该节点为leader的分区，其他节点无法同步消息（从ISR中掉队），再">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka_deadlock_analysis">
<meta property="og:url" content="http://example.com/2021/12/01/kafka-deadlock-analysis/index.html">
<meta property="og:site_name" content="Coding Heart">
<meta property="og:description" content="Kafka死锁问题                           问题现象       以数据服务团队的CUPS系统为例，upkafka-1.0版本出现的问题主要会产生如下异常现象：  文件句柄增多（能够达到40w+） CLOSE_WAIT增多（数量同样非常巨大） 单节点hang住，该节点为leader的分区，其他节点无法同步消息（从ISR中掉队），再">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/.com//kafka_deadlock_analysis.jpg">
<meta property="article:published_time" content="2021-12-01T13:47:51.000Z">
<meta property="article:modified_time" content="2021-12-01T13:49:48.818Z">
<meta property="article:author" content="Yu Jie">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/.com//kafka_deadlock_analysis.jpg"><title>kafka_deadlock_analysis | Coding Heart</title><link ref="canonical" href="http://example.com/2021/12/01/kafka-deadlock-analysis/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Coding Heart</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">kafka_deadlock_analysis</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-12-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-12-01</span></span></div></header><div class="post-body">
        <h2 id="Kafka死锁问题">
          <a href="#Kafka死锁问题" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka死锁问题" class="headerlink" title="Kafka死锁问题"></a>Kafka死锁问题</h2>
      
        <h3 id="问题现象">
          <a href="#问题现象" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h3>
      <p>以数据服务团队的CUPS系统为例，upkafka-1.0版本出现的问题主要会产生如下异常现象：</p>
<ol>
<li>文件句柄增多（能够达到40w+）</li>
<li>CLOSE_WAIT增多（数量同样非常巨大）</li>
<li>单节点hang住，该节点为leader的分区，其他节点无法同步消息（从ISR中掉队），再加上外部客户端无法连上该节点，导致分区不可用，高可用失效</li>
<li>jstack抓到死锁信息，循环等待的monitor都是a kafka.coordinator.group.GroupMetadata，wait的位置都是DelayedProduce中的方法</li>
</ol>

        <h3 id="问题梳理">
          <a href="#问题梳理" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题梳理" class="headerlink" title="问题梳理"></a>问题梳理</h3>
      <p>这里先解释下什么是延迟操作，它是Kafka中用来等待一些比较耗时的操作结果，会有Kafka内置的时间轮去控制延迟操作的最大等待时间。源码里面给了两个例子，生产者的延迟操作是等待足够数量的ACK(-1的情况下需要topic副本数个ACK，1的情况下只需要Leader副本的ACK)后进行校验；Fetch的延迟操作时等待足够字节的消息累积后进行校验，本质上Fetch跟消费是一样的，都是满足数量或者时间条件后返回批量的消息集合。</p>
<p>这里先截取jstack中抓到的deadlock部分信息：</p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Found one Java-level deadlock:</span><br><span class="line">=============================</span><br><span class="line">&quot;executor-Produce&quot;:</span><br><span class="line">  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-5&quot;</span><br><span class="line">&quot;kafka-request-handler-5&quot;:</span><br><span class="line">  waiting to lock monitor 0x00007fd83001aec8 (object 0x00000000bd7336c0, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-0&quot;</span><br><span class="line">&quot;kafka-request-handler-0&quot;:</span><br><span class="line">  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-5&quot;</span><br></pre></td></tr></table></div></figure>

<p>kafka-request-handler-0和kafka-request-handler-5的堆栈如下：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;kafka-request-handler-5&quot;</span>:</span><br><span class="line">	at kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:<span class="number">75</span>)</span><br><span class="line">	- waiting to lock &lt;<span class="number">0x00000000bd7336c0</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:<span class="number">338</span>)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:<span class="number">244</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:<span class="number">250</span>)</span><br><span class="line">	at kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:<span class="number">418</span>)</span><br><span class="line">	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:<span class="number">500</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">546</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.immutable.Map$Map1.foreach(Map.scala:<span class="number">116</span>)</span><br><span class="line">	at scala.collection.TraversableLike$class.map(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.AbstractTraversable.map(Traversable.scala:<span class="number">104</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:<span class="number">373</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:<span class="number">239</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:<span class="number">381</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:<span class="number">464</span>)</span><br><span class="line">	- locked &lt;<span class="number">0x00000000bda748b8</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:<span class="number">427</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:<span class="number">356</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handle(KafkaApis.scala:<span class="number">105</span>)</span><br><span class="line">	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:<span class="number">66</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"><span class="string">&quot;kafka-request-handler-0&quot;</span>:</span><br><span class="line">	at kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:<span class="number">75</span>)</span><br><span class="line">	- waiting to lock &lt;<span class="number">0x00000000bda748b8</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:<span class="number">338</span>)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:<span class="number">244</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:<span class="number">250</span>)</span><br><span class="line">	at kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:<span class="number">418</span>)</span><br><span class="line">	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:<span class="number">500</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">546</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.immutable.Map$Map1.foreach(Map.scala:<span class="number">116</span>)</span><br><span class="line">	at scala.collection.TraversableLike$class.map(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.AbstractTraversable.map(Traversable.scala:<span class="number">104</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:<span class="number">373</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:<span class="number">239</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:<span class="number">381</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:<span class="number">464</span>)</span><br><span class="line">	- locked &lt;<span class="number">0x00000000bd7336c0</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:<span class="number">427</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:<span class="number">356</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handle(KafkaApis.scala:<span class="number">105</span>)</span><br><span class="line">	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:<span class="number">66</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br></pre></td></tr></table></div></figure>

<p>我们在jstack文件中，发现了多个handler线程互相之间存在死锁，死锁的两次monitor都是GroupMetadata的对象。互成死锁的两条handler线程的跳转逻辑，可以参考下面这个图（整体的流程上是站在分区的维度上，先提交偏移量，后执行日志追加）：</p>
<p><img src="/.com//kafka_deadlock_analysis.jpg" alt="kafka_deadlock_analysis"></p>
<p>社区ISSUES上，大佬给出的说法是，他们从堆栈跟踪排查到在执行正常的代码逻辑时持有了消费组的锁，并在后续的追加操作中尝试锁定同一分区的所有其他组。我们可以从源码中找到，第一次加锁的位置是在doCommitOffsets处，对传入的group(GroupMetadata类型的对象）加锁了；第二次加锁的位置就是在tryCompleteWatched里，这个方法是去尝试完成Watchers中的延迟请求。</p>
<p>Watchers是延迟操作的内置类，Watchers中维护了一个ConcurrentLinkedQueue的对象，用来存所有延迟请求。而上面的tryCompleteWatched方法就是去完成这个队列中的延迟请求。本例中，Watchers类主要涉及到的变量和方法如下：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Watchers</span>(<span class="params">val key: <span class="type">Any</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> operations = <span class="keyword">new</span> <span class="type">ConcurrentLinkedQueue</span>[<span class="type">T</span>]()</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历operations，并且尝试去完成一部分延迟请求</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tryCompleteWatched</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> completed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> iter = operations.iterator()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">      <span class="keyword">val</span> curr = iter.next()</span><br><span class="line">      <span class="keyword">if</span> (curr.isCompleted) &#123;</span><br><span class="line">        <span class="comment">// 如果其他线程已经完成了，就从operations中移除</span></span><br><span class="line">        iter.remove()</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curr.safeTryComplete()) &#123;		<span class="comment">// 死锁的问题点在这里</span></span><br><span class="line">        iter.remove()</span><br><span class="line">        completed += <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (operations.isEmpty)</span><br><span class="line">      removeKeyIfEmpty(key, <span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">    completed</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>我们的死锁问题出现在safeTryComplete()方法这里，这里实际上对group进行了二次加锁，并且由于是从Watchers中的ConcurrentLinkedQueue里遍历的，group并不一定是第一次加锁时的group（有可能是别的线程已加锁过的group，因而产生死锁）：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedProduce</span>(<span class="params">delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     produceMetadata: <span class="type">ProduceMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     lockOpt: <span class="type">Option</span>[<span class="type">Object</span>] = <span class="type">None</span></span>)                    </span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">DelayedOperation</span>(delayMs) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lock = lockOpt.getOrElse(<span class="keyword">this</span>)</span><br><span class="line">  ...</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// lock即为传入的lockOpt，一级级传下来，实质是GroupMetadata对象</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">safeTryComplete</span></span>(): <span class="type">Boolean</span> = lock synchronized &#123;		</span><br><span class="line">    tryComplete()</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>PS：如果好奇group怎么传进来的话，往上倒退二次就可以找到lockOpt传入的源头。上一级是appendRecords里面创建了一个DelayedProduce对象，lockOpt为传入的delayedProduceLock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                  requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                  internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                  isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                  delayedProduceLock: <span class="type">Option</span>[<span class="type">Object</span>] = <span class="type">None</span>) &#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">// 创建一个DelayedProduce对象</span></span><br><span class="line"> <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>再往上倒退就可以清楚的看到，初始化appendRecords的实例的时候，把group(GroupMetadata对象)作为参数传进去了，也就是delayedProduceLock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendForGroup</span></span>(group: <span class="type">GroupMetadata</span>,</span><br><span class="line">                           records: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                           callback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// call replica manager to append the group message</span></span><br><span class="line">  replicaManager.appendRecords(</span><br><span class="line">    timeout = config.offsetCommitTimeoutMs.toLong,</span><br><span class="line">    requiredAcks = config.offsetCommitRequiredAcks,</span><br><span class="line">    internalTopicsAllowed = <span class="literal">true</span>,</span><br><span class="line">    isFromClient = <span class="literal">false</span>,</span><br><span class="line">    entriesPerPartition = records,</span><br><span class="line">    responseCallback = callback,</span><br><span class="line">    delayedProduceLock = <span class="type">Some</span>(group))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="修复方式">
          <a href="#修复方式" class="heading-link"><i class="fas fa-link"></i></a><a href="#修复方式" class="headerlink" title="修复方式"></a>修复方式</h3>
      
        <h4 id="循环等待消除">
          <a href="#循环等待消除" class="heading-link"><i class="fas fa-link"></i></a><a href="#循环等待消除" class="headerlink" title="循环等待消除"></a>循环等待消除</h4>
      <p>社区对该死锁问题的解决主要是解决第二次对其他的group(GroupMetadata对象)加锁的问题。</p>
<p>社区修复是在各延迟操作的父类DelayedOperation中内置了一个DelayedOperation私有对象的ReentrantLock，这个ReentrantLock是由DelayedOperation初始化的时候传入的Lock来决定的。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">DelayedOperation</span>(<span class="params">override val delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    lockOpt: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span></span>) <span class="keyword">extends</span> <span class="title">TimerTask</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>[server] <span class="keyword">val</span> lock: <span class="type">Lock</span> = lockOpt.getOrElse(<span class="keyword">new</span> <span class="type">ReentrantLock</span>)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>DelayedProduce作为DelayedOperation的子类，初始化的时候也带了一个Lock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedProduce</span>(<span class="params">delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     produceMetadata: <span class="type">ProduceMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     lockOpt: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">DelayedOperation</span>(delayMs, lockOpt) &#123;</span><br><span class="line">  ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>在appendForGroup这里，调用appendRecords的时候传入的也是group.lock(也是ReentrantLock)：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendForGroup</span></span>(group: <span class="type">GroupMetadata</span>,                             records: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],                             callback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;    <span class="comment">// call replica manager to append the group message    replicaManager.appendRecords(      timeout = config.offsetCommitTimeoutMs.toLong,      requiredAcks = config.offsetCommitRequiredAcks,      internalTopicsAllowed = true,      isFromClient = false,      entriesPerPartition = records,      delayedProduceLock = Some(group.lock),      responseCallback = callback)&#125;</span></span><br></pre></td></tr></table></div></figure>

<p>最后一级级流转，调用了DelayedOperation中的maybeTryComplete()，这里的lock就是来自于传入的group.lock。不同于之前强制进行第二次sychronized加锁的方式，这里进行了校验，如果获取锁失败的话，会直接退出。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[server] <span class="function"><span class="keyword">def</span> <span class="title">maybeTryComplete</span></span>(): <span class="type">Boolean</span> = &#123;    <span class="keyword">if</span> (lock.tryLock()) &#123;      <span class="keyword">try</span> &#123;        tryComplete()      &#125; <span class="keyword">finally</span> &#123;        lock.unlock()      &#125;    &#125; <span class="keyword">else</span>      <span class="literal">false</span>  &#125;</span><br></pre></td></tr></table></div></figure>

<p>通过这样的方式来解决“线程1加锁A-加锁B-退出B-退出A”， “线程2加锁B-加锁A-退出A-退出B”导致的死锁。</p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="http://example.com">Yu Jie</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="http://example.com/2021/12/01/kafka-deadlock-analysis/">http://example.com/2021/12/01/kafka-deadlock-analysis/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://example.com/tags/Kafka/">Kafka</a></span></div><nav class="post-paginator paginator"><div class="paginator-next"><a class="paginator-next__link" href="/2021/11/30/kafka_orders/"><span class="paginator-prev__text">Kafka常用命令</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">
          Kafka死锁问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E7%8E%B0%E8%B1%A1"><span class="toc-number">1.1.</span> <span class="toc-text">
          问题现象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%A2%B3%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">
          问题梳理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E5%A4%8D%E6%96%B9%E5%BC%8F"><span class="toc-number">1.3.</span> <span class="toc-text">
          修复方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%AA%E7%8E%AF%E7%AD%89%E5%BE%85%E6%B6%88%E9%99%A4"><span class="toc-number">1.3.1.</span> <span class="toc-text">
          循环等待消除</span></a></li></ol></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">Yuyuyyyyyy</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">2</div><div class="sidebar-ov-state-item__name">Archives</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Yu Jie</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.4.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>