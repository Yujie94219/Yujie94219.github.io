[{"title":"Kafka简单调优","url":"/2021/12/01/kafka-evolutionary/","content":"\n### Kafka简单调优\n\n应用程序层 - 框架层 - JVM层 -操作系统层，优化效果自上而下衰减\n\n <!--more--> \n\n#### 操作系统\n\n1.  禁掉atime（access time），atime会占用inode资源     \n\n    mount -o noatime\n\n2.  文件系统至少选择ext4或XFS。ZFS > XFS > ext4\n\n3.  swap空间的设置，swappiness设置在1 ~ 10，防止OOM Killer   \n\n   临时修改sudo sysctl vm.swappiness=N，永久修改/etc/sysctl.conf，增加vm.swappiness=N\n\n4.  ulimit -n/vm.max_map_count，前者会出现Too Many File Open，后者会出现OutOfMemoryError: Map failed   \n\n   修改/etc/sysctl.conf，增加vm.max_map_count=663650，保存后sysctl -p使其生效\n\n5.  预留至少一个日志端的大小（log.segment.bytes，默认1GB）\n\n#### JVM层\n\n1.  设置堆大小   6 ~ 8GB ，或者查看GC log，Full GC后存活对象总大小的1.5 ~ 2倍\n\n2.  GC收集器   G1\n\n   PS：G1这里有两个重点注意点。首先，G1的Full GC是单线程（很慢），频繁出现的话配置-XX:+PrintAdaptiveSizePolicy排查；其次，G1有区域尺寸，超过区域尺寸一半大小的对象会被分配到大对象区，可以通过增大堆或者增大区域大小，-XX:+G1HeapRegionSize=N\n\n#### Broker端\n\n客户端服务端版本保持一致，版本不一致会令Kafka丧失很多性能收益，如Zero Copy\n\n​\t低版本Consumer：Producer - PageCache - JVM Heap - Legacy Consumer\n\n​\t同版本Consumer：Producer - PageCache - Consumer\n\n#### 应用层\n\n1.  不要频繁地创建Producer和Consumer对象实例\n\n2.  用完及时关闭，Socket链接、ByteBuffer等\n\n3. 合理利用多线程，Kafka的Java Producer是线程安全，直接多线程可共享一个实例；Java Consumer非线程安全，但有消费组+分区保证\n\n#### 调优吞吐量\n\n**Broker端：**\n\n1.  适当增加num.replica.fetchers，不超过CPU核数\n\n2.  调优GC参数避免经常Full GC\n\n**Producer端：**\n\n1.  适当增加batch.size，如默认16KB增加到512KB或1MB，防止吞吐量倍副本同步性能拖累\n\n2.  适当增加linger.ms，如10 ~ 100，延迟换更少的网络传输次数，以提升吞吐\n\n3.  设置compression.type=lz4或zstd，减少网络I/O传输量，间接提升吞吐\n\n4.  设置acks=0或1\n\n5.  设置retries=0\n\n6.  如果多线程共享一个Producer实例，增加buffer.memory（尤其是出现了TimeoutException：Failed to allocate memory within the configured max blocking time）\n\n**Consumer端：**\n\n1.  采用多Consumer进程或线程同时消费\n\n2.  增加fetch.min.bytes，比如1KB或更大（表示服务端积攒了1KB或以上的数据，就可以返回给Consumer）\n\n#### 调优延时\n\n**Broker端：**\n\n同上适当增加num.replica.fetchers\n\n**Producer端：**\n\n1.  设置linger.ms=0\n\n2.  不启用压缩，compression.type=none\n\n3.  设置acks=1\n\n**Consumer端：**\n\n设置fetch.min.bytes=1（服务端积攒1字节数据就吐给Consumer）","tags":["Kafka"],"categories":["学习"]},{"title":"MySQL存储引擎","url":"/2021/12/01/mysql_storage_engine/","content":"\n### MySQL存储引擎\n\n <!--more--> \n\n#### Innodb（应用最广泛，现在默认的存储引擎）\n\n**设计目的：**\n\n用来处理大量的短期事务\n\n**重要特点：**\n\n- 支持事务\n\n- 支持行级锁\n\n- 自动崩溃恢复\n\n- 采用MVCC来支持高并发\n\n- 基于聚簇索引建立\n\n- 大量内部优化（可预测性预读、自适应哈希、插入缓冲区等）\n\n- 支持热备份（MySQL Enterprise Backup、XtraBackup也可以）\n\n**重要特性：**\n\n- 利用排序创建索引\n\n- 删除或者增加索引时不需要复制全表数据\n\n- 新的支持压缩的存储格式\n\n- 新的大型列值如BLOB的存储方式\n\n- 文件格式管理\n\n#### MyISAM（5.1及之前的默认存储引擎）\n\n**重要特点：**\n\n- 默认只能处理256TB（因为指针长度是6字节，最多可以修改到8字节，MAX_ROWS和AVG_ROW_LENGTH)\n\n- 表存储在两个文件（.MYD存数据文件, .MYI存索引文件）\n\n**重要特性：**\n\n- 表级锁，读表共享锁，写表排他锁（但是可以通过并发插入，在读表的时候插入新记录）\n\n- 支持修复（有可能会丢失数据）\n\n- 全文索引（基于分词创建）\n\n- 对BLOB和TEXT等长字段，可以基于前500个字符创建索引\n\n- 延迟更新索引键（DELAY_KEY_WRITE，索引修改写入到内存钟的键缓冲区，键缓冲区加Mutex锁，在清理缓冲区或关闭表时写入磁盘。极大提升了性能，但有可能在异常情况下造成索引损坏）\n\n- 压缩表（只读，支持索引且索引也只读。可以减少磁盘空间占用，减少磁盘IO）\n\n- 空间函数（支持地理空间搜索）\n\n**主要缺陷：**\n\n- 不支持事务\n\n- 不支持行级锁（并发写入的性能较低）\n\n- 崩溃后无法安全恢复\n\n#### Archive（针对插入和压缩做了优化的简单引擎）\n\n**重要特点：**\n\n- 只支持INSERT和SELECT\n\n- 支持行级锁\n\n- 支持专用的缓冲区\n\n- 缓存所有的写并利用zlib对插入行进行压缩（磁盘I/O比MyISAM更少）\n\n**重要特性：**\n\n- 一个查询返回表中存在的所有行数前，阻止其他的SELECT执行（保证一致性读）\n\n- 批量插入完成前对读操作不可见（模仿了事务机制和MVCC）\n\n**适用场景：**\n\n1. 日志数据采集类应用\n\n2. 需要更快INSERT操作\n\n#### Blackhole（仅可作为特殊的复制架构和日志审核手段）（经常带来问题，不推荐使用）\n\n#### CSV（作为数据交换的机制）\n\n**重要特点：**\n\n- 可以将CSV文件作为表（CSV作为表不支持索引）\n\n- 可以在数据库运行时拷入或拷出文件\n\n**适用场景：**\n\n- Excel等电子表格软件中的数据快速存入MySQL\n\n- 外部程序需要立即从表的数据文件中读取CSV格式的数据\n\n#### Federated（提供跨服务器的灵活性）（经常带来问题，默认禁用）\n\n**设计目的：**\n\n为了和Microsoft SQL Server和Oracle竞争\n\n**重要特点：**\n\n- 其他MySQL服务器的一个代理\n\n- 能够建立远程MySQL连接，将查询传输到远程服务器上执行\n\n#### Memory（早期叫HEAP，内存数据引擎，超快访问速度）：\n\n**重要特点：**\n\n- 数据都存在内存中（不需要磁盘I/O，查询速度至少比MyISAM快一个数量级）\n\n- 重启后会保留表结构，但数据会丢失\n\n- 支持Hash索引\n\n**主要缺陷：**\n\n- 仅支持表级锁（并发写入的性能较低）\n\n- 不支持BLOB或TEXT类型的列\n\n- 每行的长度固定（即使指定VARCHAR，实际存储也会转换成CHAR，可能导致内存浪费）\n\n**适用场景：**\n\n1. 用于查找或映射表\n\n2. 用于缓存周期性聚合数据的结果\n\n3. 用于保存数据分析中产生的中间数据\n\n4. MySQL内部使用的临时表（如果MySQL查询中间结果太大超过了Memory表的限制，或包含BLOB或TEXT字段，临时表自动转换为MyISAM）\n\n#### Merge（用于日志或者数据仓库类应用，被MySQL分区功能完全击败，已放弃）\n\n**重要特点：**\n\n- 很多特点类同MyISAM（MyISAM的变种）\n\n- 多个MyISAM表合并出来的虚拟表\n\n#### NDB（集群引擎）\n\n**重要特点：**\n\n多MySQL服务器+NDB集群存储引擎+NDB数据库（保证分布式、share-nothing、容灾及高可用）=MySQL集群\n\n#### 第三方存储引擎\n\n* OLTP类引擎（XtraDB、PBXT）\n\n* 面向列的引擎（Infobright）\n\n* 社区引擎（Aria、Groonga、OQGraph、Q4M、SphinxSE、Spider、VPForMySQL）","tags":["mysql"],"categories":["学习"]},{"title":"kafka_deadlock_analysis","url":"/2021/12/01/kafka-deadlock-analysis/","content":"\n## Kafka死锁问题\n\n### 问题现象\n\nkafka_0.11.0.0版本出现的问题主要会产生如下异常现象：\n\n1. 文件句柄增多（能够达到40w+）\n2. CLOSE_WAIT增多（数量同样非常巨大）\n3. 单节点hang住，该节点为leader的分区，其他节点无法同步消息（从ISR中掉队），再加上外部客户端无法连上该节点，导致分区不可用，高可用失效\n4. jstack抓到死锁信息，循环等待的monitor都是a kafka.coordinator.group.GroupMetadata，wait的位置都是DelayedProduce中的方法\n\n <!--more--> \n\n### 问题梳理\n\n这里先解释下什么是延迟操作，它是Kafka中用来等待一些比较耗时的操作结果，会有Kafka内置的时间轮去控制延迟操作的最大等待时间。源码里面给了两个例子，生产者的延迟操作是等待足够数量的ACK(-1的情况下需要topic副本数个ACK，1的情况下只需要Leader副本的ACK)后进行校验；Fetch的延迟操作时等待足够字节的消息累积后进行校验，本质上Fetch跟消费是一样的，都是满足数量或者时间条件后返回批量的消息集合。\n\n这里先截取jstack中抓到的deadlock部分信息：\n\n```\nFound one Java-level deadlock:\n=============================\n\"executor-Produce\":\n  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),\n  which is held by \"kafka-request-handler-5\"\n\"kafka-request-handler-5\":\n  waiting to lock monitor 0x00007fd83001aec8 (object 0x00000000bd7336c0, a kafka.coordinator.group.GroupMetadata),\n  which is held by \"kafka-request-handler-0\"\n\"kafka-request-handler-0\":\n  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),\n  which is held by \"kafka-request-handler-5\"\n```\n\nkafka-request-handler-0和kafka-request-handler-5的堆栈如下：\n\n```java\n\"kafka-request-handler-5\":\n\tat kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:75)\n\t- waiting to lock <0x00000000bd7336c0> (a kafka.coordinator.group.GroupMetadata)\n\tat kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:338)\n\tat kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:244)\n\tat kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:250)\n\tat kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:418)\n\tat kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:500)\n\tat kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:546)\n\tat kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:532)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:116)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:532)\n\tat kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:373)\n\tat kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:239)\n\tat kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:381)\n\tat kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:464)\n\t- locked <0x00000000bda748b8> (a kafka.coordinator.group.GroupMetadata)\n\tat kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:427)\n\tat kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:356)\n\tat kafka.server.KafkaApis.handle(KafkaApis.scala:105)\n\tat kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:66)\n\tat java.lang.Thread.run(Thread.java:745)\n\"kafka-request-handler-0\":\n\tat kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:75)\n\t- waiting to lock <0x00000000bda748b8> (a kafka.coordinator.group.GroupMetadata)\n\tat kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:338)\n\tat kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:244)\n\tat kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:250)\n\tat kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:418)\n\tat kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:500)\n\tat kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:546)\n\tat kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:532)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.Map$Map1.foreach(Map.scala:116)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:532)\n\tat kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:373)\n\tat kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:239)\n\tat kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:381)\n\tat kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:464)\n\t- locked <0x00000000bd7336c0> (a kafka.coordinator.group.GroupMetadata)\n\tat kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:427)\n\tat kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:356)\n\tat kafka.server.KafkaApis.handle(KafkaApis.scala:105)\n\tat kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:66)\n\tat java.lang.Thread.run(Thread.java:745)\n```\n\n我们在jstack文件中，发现了多个handler线程互相之间存在死锁，死锁的两次monitor都是GroupMetadata的对象。互成死锁的两条handler线程的跳转逻辑，可以参考下面这个图（整体的流程上是站在分区的维度上，先提交偏移量，后执行日志追加）：\n\n![kafka_deadlock_analysis](kafka_deadlock_analysis.jpg)\n\n社区ISSUES上，大佬给出的说法是，他们从堆栈跟踪排查到在执行正常的代码逻辑时持有了消费组的锁，并在后续的追加操作中尝试锁定同一分区的所有其他组。我们可以从源码中找到，第一次加锁的位置是在doCommitOffsets处，对传入的group(GroupMetadata类型的对象）加锁了；第二次加锁的位置就是在tryCompleteWatched里，这个方法是去尝试完成Watchers中的延迟请求。\n\nWatchers是延迟操作的内置类，Watchers中维护了一个ConcurrentLinkedQueue的对象，用来存所有延迟请求。而上面的tryCompleteWatched方法就是去完成这个队列中的延迟请求。本例中，Watchers类主要涉及到的变量和方法如下：\n\n```Scala\nprivate class Watchers(val key: Any) {\n  private[this] val operations = new ConcurrentLinkedQueue[T]()\n  ...\n\n  // 遍历operations，并且尝试去完成一部分延迟请求\n  def tryCompleteWatched(): Int = {\n    var completed = 0\n\n    val iter = operations.iterator()\n    while (iter.hasNext) {\n      val curr = iter.next()\n      if (curr.isCompleted) {\n        // 如果其他线程已经完成了，就从operations中移除\n        iter.remove()\n      } else if (curr.safeTryComplete()) {\t\t// 死锁的问题点在这里\n        iter.remove()\n        completed += 1\n      }\n    }\n\n    if (operations.isEmpty)\n      removeKeyIfEmpty(key, this)\n\n    completed\n  }\n  ...\n}\n```\n\n我们的死锁问题出现在safeTryComplete()方法这里，这里实际上对group进行了二次加锁，并且由于是从Watchers中的ConcurrentLinkedQueue里遍历的，group并不一定是第一次加锁时的group（有可能是别的线程已加锁过的group，因而产生死锁）：\n\n```scala\nclass DelayedProduce(delayMs: Long,\n                     produceMetadata: ProduceMetadata,\n                     replicaManager: ReplicaManager,\n                     responseCallback: Map[TopicPartition, PartitionResponse] => Unit,\n                     lockOpt: Option[Object] = None)                    \n  extends DelayedOperation(delayMs) {\n\n  val lock = lockOpt.getOrElse(this)\n  ...\n  \n  // lock即为传入的lockOpt，一级级传下来，实质是GroupMetadata对象\n  override def safeTryComplete(): Boolean = lock synchronized {\t\t\n    tryComplete()\n  }\n  ...\n}\n```\n\nPS：如果好奇group怎么传进来的话，往上倒退二次就可以找到lockOpt传入的源头。上一级是appendRecords里面创建了一个DelayedProduce对象，lockOpt为传入的delayedProduceLock：\n\n```scala\ndef appendRecords(timeout: Long,\n                  requiredAcks: Short,\n                  internalTopicsAllowed: Boolean,\n                  isFromClient: Boolean,\n                  entriesPerPartition: Map[TopicPartition, MemoryRecords],\n                  responseCallback: Map[TopicPartition, PartitionResponse] => Unit,\n                  delayedProduceLock: Option[Object] = None) {\n ...\n // 创建一个DelayedProduce对象\n val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback, delayedProduceLock)\n ...\n}\n```\n\n再往上倒退就可以清楚的看到，初始化appendRecords的实例的时候，把group(GroupMetadata对象)作为参数传进去了，也就是delayedProduceLock：\n\n```scala\nprivate def appendForGroup(group: GroupMetadata,\n                           records: Map[TopicPartition, MemoryRecords],\n                           callback: Map[TopicPartition, PartitionResponse] => Unit): Unit = {\n  // call replica manager to append the group message\n  replicaManager.appendRecords(\n    timeout = config.offsetCommitTimeoutMs.toLong,\n    requiredAcks = config.offsetCommitRequiredAcks,\n    internalTopicsAllowed = true,\n    isFromClient = false,\n    entriesPerPartition = records,\n    responseCallback = callback,\n    delayedProduceLock = Some(group))\n}\n```\n\n### 修复方式\n\n#### 循环等待消除\n\n社区对该死锁问题的解决主要是解决第二次对其他的group(GroupMetadata对象)加锁的问题。\n\n社区修复是在各延迟操作的父类DelayedOperation中内置了一个DelayedOperation私有对象的ReentrantLock，这个ReentrantLock是由DelayedOperation初始化的时候传入的Lock来决定的。\n\n```scala\nabstract class DelayedOperation(override val delayMs: Long,\n    lockOpt: Option[Lock] = None) extends TimerTask with Logging {\n  ...\n  private[server] val lock: Lock = lockOpt.getOrElse(new ReentrantLock)\n  ...\n}\n```\n\nDelayedProduce作为DelayedOperation的子类，初始化的时候也带了一个Lock：\n\n```scala\nclass DelayedProduce(delayMs: Long,\n                     produceMetadata: ProduceMetadata,\n                     replicaManager: ReplicaManager,\n                     responseCallback: Map[TopicPartition, PartitionResponse] => Unit,\n                     lockOpt: Option[Lock] = None)\n  extends DelayedOperation(delayMs, lockOpt) {\n  ... \n}\n```\n\n在appendForGroup这里，调用appendRecords的时候传入的也是group.lock(也是ReentrantLock)：\n\n```scala\nprivate def appendForGroup(group: GroupMetadata,                             records: Map[TopicPartition, MemoryRecords],                             callback: Map[TopicPartition, PartitionResponse] => Unit): Unit = {    // call replica manager to append the group message    replicaManager.appendRecords(      timeout = config.offsetCommitTimeoutMs.toLong,      requiredAcks = config.offsetCommitRequiredAcks,      internalTopicsAllowed = true,      isFromClient = false,      entriesPerPartition = records,      delayedProduceLock = Some(group.lock),      responseCallback = callback)}\n```\n\n最后一级级流转，调用了DelayedOperation中的maybeTryComplete()，这里的lock就是来自于传入的group.lock。不同于之前强制进行第二次sychronized加锁的方式，这里进行了校验，如果获取锁失败的话，会直接退出。\n\n```scala\n  private[server] def maybeTryComplete(): Boolean = {    if (lock.tryLock()) {      try {        tryComplete()      } finally {        lock.unlock()      }    } else      false  }\n```\n\n通过这样的方式来解决“线程1加锁A-加锁B-退出B-退出A”， “线程2加锁B-加锁A-退出A-退出B”导致的死锁。\n","tags":["Kafka"],"categories":["学习"]},{"title":"Kafka常用命令","url":"/2021/11/30/kafka_orders/","content":"\n### Kafka常用命令\n\n记录工作中用的比较多的Kafka脚本命令。\n\n <!--more--> \n\n#### 节点命令\n\n- 启动：bin/kafka-server-start.sh config/server.properties\n\n- 停止：bin/kafka-server-stop.sh\n- 消费者压测工具：bin/kafka-consumer-perf-test.sh --messages 100000 --message-size 500 --broker-list 172.21.36.29:9093,172.21.36.180:9092,172.21.36.30:9094 --threads 20 --num-fetch-threads 20 --batch-size 500 --consumer.config ./config/consumer.properties --topic test11\n- 生产者压测工具：bin/kafka-producer-perf-test.sh --num-records 1000 --record-size 5 --throughput 10000 --producer-props bootstrap.servers=172.21.36.29:9093,172.21.36.180:9092,172.21.36.30:9094 --topic test\n\n- 最简单版生产消息：bin/kafka-console-producer.sh -broker-list 192.168.130.128:9092 -topic test\n\n    如果要发送key：bin/kafka-console-producer.sh --broker-list 192.168.130.128:9092 -topic test --property parse.key=true --property key.separator=\":\"\n\n- 新消费者消费消息：bin/kafka-console-consumer.sh --bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 --topic test --new-consumer --from-beginning --consumer.config config/consumer.properties\n\n   如果要看key：bin/kafka-console-consumer.sh --bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 --topic test --new-consumer --from-beginning --consumer.config config/consumer.properties --property print.key=true --property key.separator=\":\"\n\n#### Topic命令\n\n- 新建topic：bin/kafka-topics.sh -create -zookeeper 192.168.130.128:2181 -replication-factor 2 -partitions 4 -topic test\n\n- 查询指定topic的LogSize：bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 192.168.130.128:9092 --topic test --time -1\n\n- 分区工具三部曲：\n\n  bin/kafka-reassign-partitions.sh --zookeeper 192.168.130.128:2181 --topics-to-move-json-file ./bin/topics-to-move.json --broker-list \"2\" --generate\n\n  bin/kafka-reassign-partitions.sh --zookeeper 192.168.130.128:2181 --reassignment-json-file ./bin/reassignment.json --execute\n\n  bin/kafka-reassign-partitions.sh --zookeeper 192.168.130.128:2181 --reassignment-json-file ./bin/reassignment.json --verify\n\n#### 消费组命令\n\n- 查询消费组消费进度（0.8）：bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --topic test1 --zookeeper 192.168.130.128:2181 --group offset-father\n\n- 查询消费组消费进度：bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 --group offset-father --describe\n\n- 自定义设置开始偏移量：/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.130.128:9092 --group offset-father --topic test1 --execute --reset-offsets --to-earliest\n","tags":["Kafka"],"categories":["学习"]}]