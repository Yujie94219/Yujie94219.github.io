<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="Coding Heart">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Coding Heart">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yu Jie">
<meta name="twitter:card" content="summary"><title>Coding Heart</title><link ref="canonical" href="http://example.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Coding Heart</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/11/30/Kafka/Kafka%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">Kafka常用命令</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-11-30</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-11-30</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="Kafka常用命令"   >
          <a href="#Kafka常用命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h3>
      
        <h4 id="节点命令"   >
          <a href="#节点命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#节点命令" class="headerlink" title="节点命令"></a>节点命令</h4>
      <ul>
<li><p>启动：bin/kafka-server-start.sh config/server.properties</p>
</li>
<li><p>停止：bin/kafka-server-stop.sh</p>
</li>
<li><p>消费者压测工具：bin/kafka-consumer-perf-test.sh –messages 100000 –message-size 500 –broker-list 172.21.36.29:9093,172.21.36.180:9092,172.21.36.30:9094 –threads 20 –num-fetch-threads 20 –batch-size 500 –consumer.config ./config/consumer.properties –topic test11</p>
</li>
<li><p>生产者压测工具：bin/kafka-producer-perf-test.sh –num-records 1000 –record-size 5 –throughput 10000 –producer-props bootstrap.servers=172.21.36.29:9093,172.21.36.180:9092,172.21.36.30:9094 –topic test</p>
</li>
<li><p>最简单版生产消息：bin/kafka-console-producer.sh -broker-list 192.168.130.128:9092 -topic test</p>
<p>  如果要发送key：bin/kafka-console-producer.sh –broker-list 192.168.130.128:9092 -topic test –property parse.key=true –property key.separator=”:”</p>
</li>
<li><p>新消费者消费消息：bin/kafka-console-consumer.sh –bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 –topic test –new-consumer –from-beginning –consumer.config config/consumer.properties</p>
<p> 如果要看key：bin/kafka-console-consumer.sh –bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 –topic test –new-consumer –from-beginning –consumer.config config/consumer.properties –property print.key=true –property key.separator=”:”</p>
</li>
</ul>

        <h4 id="Topic命令"   >
          <a href="#Topic命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#Topic命令" class="headerlink" title="Topic命令"></a>Topic命令</h4>
      <ul>
<li><p>新建topic：bin/kafka-topics.sh -create -zookeeper 192.168.130.128:2181 -replication-factor 2 -partitions 4 -topic test</p>
</li>
<li><p>查询指定topic的LogSize：bin/kafka-run-class.sh kafka.tools.GetOffsetShell –broker-list 192.168.130.128:9092 –topic test –time -1</p>
</li>
<li><p>分区工具三部曲：</p>
<p>bin/kafka-reassign-partitions.sh –zookeeper 192.168.130.128:2181 –topics-to-move-json-file ./bin/topics-to-move.json –broker-list “2” –generate</p>
<p>bin/kafka-reassign-partitions.sh –zookeeper 192.168.130.128:2181 –reassignment-json-file ./bin/reassignment.json –execute</p>
<p>bin/kafka-reassign-partitions.sh –zookeeper 192.168.130.128:2181 –reassignment-json-file ./bin/reassignment.json –verify</p>
</li>
</ul>

        <h4 id="消费组命令"   >
          <a href="#消费组命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#消费组命令" class="headerlink" title="消费组命令"></a>消费组命令</h4>
      <ul>
<li><p>查询消费组消费进度（0.8）：bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker –topic test1 –zookeeper 192.168.130.128:2181 –group offset-father</p>
</li>
<li><p>查询消费组消费进度：bin/kafka-consumer-groups.sh –new-consumer –bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 –group offset-father –describe</p>
</li>
<li><p>自定义设置开始偏移量：/bin/kafka-consumer-groups.sh –bootstrap-server 192.168.130.128:9092 –group offset-father –topic test1 –execute –reset-offsets –to-earliest</p>
</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/11/30/Kafka/Kafka%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90(0.11.0.0%E7%89%88%E6%9C%AC)/">Kafka死锁问题</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-11-30</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-11-30</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="Kafka死锁问题"   >
          <a href="#Kafka死锁问题" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka死锁问题" class="headerlink" title="Kafka死锁问题"></a>Kafka死锁问题</h2>
      
        <h3 id="问题现象"   >
          <a href="#问题现象" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h3>
      <p>以数据服务团队的CUPS系统为例，upkafka-1.0版本出现的问题主要会产生如下异常现象：</p>
<ol>
<li>文件句柄增多（能够达到40w+）</li>
<li>CLOSE_WAIT增多（数量同样非常巨大）</li>
<li>单节点hang住，该节点为leader的分区，其他节点无法同步消息（从ISR中掉队），再加上外部客户端无法连上该节点，导致分区不可用，高可用失效</li>
<li>jstack抓到死锁信息，循环等待的monitor都是a kafka.coordinator.group.GroupMetadata，wait的位置都是DelayedProduce中的方法</li>
</ol>

        <h3 id="问题梳理"   >
          <a href="#问题梳理" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题梳理" class="headerlink" title="问题梳理"></a>问题梳理</h3>
      <p>这里先解释下什么是延迟操作，它是Kafka中用来等待一些比较耗时的操作结果，会有Kafka内置的时间轮去控制延迟操作的最大等待时间。源码里面给了两个例子，生产者的延迟操作是等待足够数量的ACK(-1的情况下需要topic副本数个ACK，1的情况下只需要Leader副本的ACK)后进行校验；Fetch的延迟操作时等待足够字节的消息累积后进行校验，本质上Fetch跟消费是一样的，都是满足数量或者时间条件后返回批量的消息集合。</p>
<p>这里先截取jstack中抓到的deadlock部分信息：</p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Found one Java-level deadlock:</span><br><span class="line">=============================</span><br><span class="line">&quot;executor-Produce&quot;:</span><br><span class="line">  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-5&quot;</span><br><span class="line">&quot;kafka-request-handler-5&quot;:</span><br><span class="line">  waiting to lock monitor 0x00007fd83001aec8 (object 0x00000000bd7336c0, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-0&quot;</span><br><span class="line">&quot;kafka-request-handler-0&quot;:</span><br><span class="line">  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-5&quot;</span><br></pre></td></tr></table></div></figure>

<p>kafka-request-handler-0和kafka-request-handler-5的堆栈如下：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;kafka-request-handler-5&quot;</span>:</span><br><span class="line">	at kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:<span class="number">75</span>)</span><br><span class="line">	- waiting to lock &lt;<span class="number">0x00000000bd7336c0</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:<span class="number">338</span>)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:<span class="number">244</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:<span class="number">250</span>)</span><br><span class="line">	at kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:<span class="number">418</span>)</span><br><span class="line">	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:<span class="number">500</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">546</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.immutable.Map$Map1.foreach(Map.scala:<span class="number">116</span>)</span><br><span class="line">	at scala.collection.TraversableLike$class.map(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.AbstractTraversable.map(Traversable.scala:<span class="number">104</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:<span class="number">373</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:<span class="number">239</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:<span class="number">381</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:<span class="number">464</span>)</span><br><span class="line">	- locked &lt;<span class="number">0x00000000bda748b8</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:<span class="number">427</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:<span class="number">356</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handle(KafkaApis.scala:<span class="number">105</span>)</span><br><span class="line">	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:<span class="number">66</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"><span class="string">&quot;kafka-request-handler-0&quot;</span>:</span><br><span class="line">	at kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:<span class="number">75</span>)</span><br><span class="line">	- waiting to lock &lt;<span class="number">0x00000000bda748b8</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:<span class="number">338</span>)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:<span class="number">244</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:<span class="number">250</span>)</span><br><span class="line">	at kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:<span class="number">418</span>)</span><br><span class="line">	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:<span class="number">500</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">546</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.immutable.Map$Map1.foreach(Map.scala:<span class="number">116</span>)</span><br><span class="line">	at scala.collection.TraversableLike$class.map(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.AbstractTraversable.map(Traversable.scala:<span class="number">104</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:<span class="number">373</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:<span class="number">239</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:<span class="number">381</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:<span class="number">464</span>)</span><br><span class="line">	- locked &lt;<span class="number">0x00000000bd7336c0</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:<span class="number">427</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:<span class="number">356</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handle(KafkaApis.scala:<span class="number">105</span>)</span><br><span class="line">	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:<span class="number">66</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br></pre></td></tr></table></div></figure>

<p>我们在jstack文件中，发现了多个handler线程互相之间存在死锁，死锁的两次monitor都是GroupMetadata的对象。互成死锁的两条handler线程的跳转逻辑，可以参考下面这个图（整体的流程上是站在分区的维度上，先提交偏移量，后执行日志追加）：</p>
<p><img src="./Kafka%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90.jpg" alt="Kafka死锁分析"></p>
<p>社区ISSUES上，大佬给出的说法是，他们从堆栈跟踪排查到在执行正常的代码逻辑时持有了消费组的锁，并在后续的追加操作中尝试锁定同一分区的所有其他组。我们可以从源码中找到，第一次加锁的位置是在doCommitOffsets处，对传入的group(GroupMetadata类型的对象）加锁了；第二次加锁的位置就是在tryCompleteWatched里，这个方法是去尝试完成Watchers中的延迟请求。</p>
<p>Watchers是延迟操作的内置类，Watchers中维护了一个ConcurrentLinkedQueue的对象，用来存所有延迟请求。而上面的tryCompleteWatched方法就是去完成这个队列中的延迟请求。本例中，Watchers类主要涉及到的变量和方法如下：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Watchers</span>(<span class="params">val key: <span class="type">Any</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> operations = <span class="keyword">new</span> <span class="type">ConcurrentLinkedQueue</span>[<span class="type">T</span>]()</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历operations，并且尝试去完成一部分延迟请求</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tryCompleteWatched</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> completed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> iter = operations.iterator()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">      <span class="keyword">val</span> curr = iter.next()</span><br><span class="line">      <span class="keyword">if</span> (curr.isCompleted) &#123;</span><br><span class="line">        <span class="comment">// 如果其他线程已经完成了，就从operations中移除</span></span><br><span class="line">        iter.remove()</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curr.safeTryComplete()) &#123;		<span class="comment">// 死锁的问题点在这里</span></span><br><span class="line">        iter.remove()</span><br><span class="line">        completed += <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (operations.isEmpty)</span><br><span class="line">      removeKeyIfEmpty(key, <span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">    completed</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>我们的死锁问题出现在safeTryComplete()方法这里，这里实际上对group进行了二次加锁，并且由于是从Watchers中的ConcurrentLinkedQueue里遍历的，group并不一定是第一次加锁时的group（有可能是别的线程已加锁过的group，因而产生死锁）：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedProduce</span>(<span class="params">delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     produceMetadata: <span class="type">ProduceMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     lockOpt: <span class="type">Option</span>[<span class="type">Object</span>] = <span class="type">None</span></span>)                    </span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">DelayedOperation</span>(delayMs) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lock = lockOpt.getOrElse(<span class="keyword">this</span>)</span><br><span class="line">  ...</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// lock即为传入的lockOpt，一级级传下来，实质是GroupMetadata对象</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">safeTryComplete</span></span>(): <span class="type">Boolean</span> = lock synchronized &#123;		</span><br><span class="line">    tryComplete()</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>PS：如果好奇group怎么传进来的话，往上倒退二次就可以找到lockOpt传入的源头。上一级是appendRecords里面创建了一个DelayedProduce对象，lockOpt为传入的delayedProduceLock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                  requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                  internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                  isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                  delayedProduceLock: <span class="type">Option</span>[<span class="type">Object</span>] = <span class="type">None</span>) &#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">// 创建一个DelayedProduce对象</span></span><br><span class="line"> <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>再往上倒退就可以清楚的看到，初始化appendRecords的实例的时候，把group(GroupMetadata对象)作为参数传进去了，也就是delayedProduceLock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendForGroup</span></span>(group: <span class="type">GroupMetadata</span>,</span><br><span class="line">                           records: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                           callback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// call replica manager to append the group message</span></span><br><span class="line">  replicaManager.appendRecords(</span><br><span class="line">    timeout = config.offsetCommitTimeoutMs.toLong,</span><br><span class="line">    requiredAcks = config.offsetCommitRequiredAcks,</span><br><span class="line">    internalTopicsAllowed = <span class="literal">true</span>,</span><br><span class="line">    isFromClient = <span class="literal">false</span>,</span><br><span class="line">    entriesPerPartition = records,</span><br><span class="line">    responseCallback = callback,</span><br><span class="line">    delayedProduceLock = <span class="type">Some</span>(group))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="修复方式"   >
          <a href="#修复方式" class="heading-link"><i class="fas fa-link"></i></a><a href="#修复方式" class="headerlink" title="修复方式"></a>修复方式</h3>
      
        <h4 id="循环等待消除"   >
          <a href="#循环等待消除" class="heading-link"><i class="fas fa-link"></i></a><a href="#循环等待消除" class="headerlink" title="循环等待消除"></a>循环等待消除</h4>
      <p>社区对该死锁问题的解决主要是解决第二次对其他的group(GroupMetadata对象)加锁的问题。</p>
<p>社区修复是在各延迟操作的父类DelayedOperation中内置了一个DelayedOperation私有对象的ReentrantLock，这个ReentrantLock是由DelayedOperation初始化的时候传入的Lock来决定的。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">DelayedOperation</span>(<span class="params">override val delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    lockOpt: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span></span>) <span class="keyword">extends</span> <span class="title">TimerTask</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>[server] <span class="keyword">val</span> lock: <span class="type">Lock</span> = lockOpt.getOrElse(<span class="keyword">new</span> <span class="type">ReentrantLock</span>)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>DelayedProduce作为DelayedOperation的子类，初始化的时候也带了一个Lock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedProduce</span>(<span class="params">delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     produceMetadata: <span class="type">ProduceMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     lockOpt: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">DelayedOperation</span>(delayMs, lockOpt) &#123;</span><br><span class="line">  ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>在appendForGroup这里，调用appendRecords的时候传入的也是group.lock(也是ReentrantLock)：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendForGroup</span></span>(group: <span class="type">GroupMetadata</span>,</span><br><span class="line">                             records: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                             callback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// call replica manager to append the group message</span></span><br><span class="line">    replicaManager.appendRecords(</span><br><span class="line">      timeout = config.offsetCommitTimeoutMs.toLong,</span><br><span class="line">      requiredAcks = config.offsetCommitRequiredAcks,</span><br><span class="line">      internalTopicsAllowed = <span class="literal">true</span>,</span><br><span class="line">      isFromClient = <span class="literal">false</span>,</span><br><span class="line">      entriesPerPartition = records,</span><br><span class="line">      delayedProduceLock = <span class="type">Some</span>(group.lock),</span><br><span class="line">      responseCallback = callback)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>最后一级级流转，调用了DelayedOperation中的maybeTryComplete()，这里的lock就是来自于传入的group.lock。不同于之前强制进行第二次sychronized加锁的方式，这里进行了校验，如果获取锁失败的话，会直接退出。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[server] <span class="function"><span class="keyword">def</span> <span class="title">maybeTryComplete</span></span>(): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (lock.tryLock()) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      tryComplete()</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      lock.unlock()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span></span><br><span class="line">    <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>通过这样的方式来解决“线程1加锁A-加锁B-退出B-退出A”， “线程2加锁B-加锁A-退出A-退出B”导致的死锁。</p>
</div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">2</div><div class="sidebar-ov-state-item__name">Archives</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Yu Jie</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.4.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>