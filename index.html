<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="Coding Heart">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Coding Heart">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yu Jie">
<meta name="twitter:card" content="summary"><title>Coding Heart</title><link ref="canonical" href="http://example.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Coding Heart</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/12/01/kafka-evolutionary/">Kafka简单调优</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-12-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-12-01</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="Kafka简单调优">
          <a href="#Kafka简单调优" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka简单调优" class="headerlink" title="Kafka简单调优"></a>Kafka简单调优</h3>
      <p>应用程序层 - 框架层 - JVM层 -操作系统层，优化效果自上而下衰减</p>

        <h4 id="操作系统">
          <a href="#操作系统" class="heading-link"><i class="fas fa-link"></i></a><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h4>
      <ol>
<li><p>禁掉atime（access time），atime会占用inode资源     </p>
<p> mount -o noatime</p>
</li>
<li><p> 文件系统至少选择ext4或XFS。ZFS &gt; XFS &gt; ext4</p>
</li>
<li><p> swap空间的设置，swappiness设置在1 ~ 10，防止OOM Killer   </p>
</li>
</ol>
<p>   临时修改sudo sysctl vm.swappiness=N，永久修改/etc/sysctl.conf，增加vm.swappiness=N</p>
<ol start="4">
<li> ulimit -n/vm.max_map_count，前者会出现Too Many File Open，后者会出现OutOfMemoryError: Map failed   </li>
</ol>
<p>   修改/etc/sysctl.conf，增加vm.max_map_count=663650，保存后sysctl -p使其生效</p>
<ol start="5">
<li> 预留至少一个日志端的大小（log.segment.bytes，默认1GB）</li>
</ol>

        <h4 id="JVM层">
          <a href="#JVM层" class="heading-link"><i class="fas fa-link"></i></a><a href="#JVM层" class="headerlink" title="JVM层"></a>JVM层</h4>
      <ol>
<li><p> 设置堆大小   6 ~ 8GB ，或者查看GC log，Full GC后存活对象总大小的1.5 ~ 2倍</p>
</li>
<li><p> GC收集器   G1</p>
</li>
</ol>
<p>   PS：G1这里有两个重点注意点。首先，G1的Full GC是单线程（很慢），频繁出现的话配置-XX:+PrintAdaptiveSizePolicy排查；其次，G1有区域尺寸，超过区域尺寸一半大小的对象会被分配到大对象区，可以通过增大堆或者增大区域大小，-XX:+G1HeapRegionSize=N</p>

        <h4 id="Broker端">
          <a href="#Broker端" class="heading-link"><i class="fas fa-link"></i></a><a href="#Broker端" class="headerlink" title="Broker端"></a>Broker端</h4>
      <p>客户端服务端版本保持一致，版本不一致会令Kafka丧失很多性能收益，如Zero Copy</p>
<p>​    低版本Consumer：Producer - PageCache - JVM Heap - Legacy Consumer</p>
<p>​    同版本Consumer：Producer - PageCache - Consumer</p>

        <h4 id="应用层">
          <a href="#应用层" class="heading-link"><i class="fas fa-link"></i></a><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h4>
      <ol>
<li><p> 不要频繁地创建Producer和Consumer对象实例</p>
</li>
<li><p> 用完及时关闭，Socket链接、ByteBuffer等</p>
</li>
<li><p>合理利用多线程，Kafka的Java Producer是线程安全，直接多线程可共享一个实例；Java Consumer非线程安全，但有消费组+分区保证</p>
</li>
</ol>

        <h4 id="调优吞吐量">
          <a href="#调优吞吐量" class="heading-link"><i class="fas fa-link"></i></a><a href="#调优吞吐量" class="headerlink" title="调优吞吐量"></a>调优吞吐量</h4>
      <p><strong>Broker端：</strong></p>
<ol>
<li><p> 适当增加num.replica.fetchers，不超过CPU核数</p>
</li>
<li><p> 调优GC参数避免经常Full GC</p>
</li>
</ol>
<p><strong>Producer端：</strong></p>
<ol>
<li><p> 适当增加batch.size，如默认16KB增加到512KB或1MB，防止吞吐量倍副本同步性能拖累</p>
</li>
<li><p> 适当增加linger.ms，如10 ~ 100，延迟换更少的网络传输次数，以提升吞吐</p>
</li>
<li><p> 设置compression.type=lz4或zstd，减少网络I/O传输量，间接提升吞吐</p>
</li>
<li><p> 设置acks=0或1</p>
</li>
<li><p> 设置retries=0</p>
</li>
<li><p> 如果多线程共享一个Producer实例，增加buffer.memory（尤其是出现了TimeoutException：Failed to allocate memory within the configured max blocking time）</p>
</li>
</ol>
<p><strong>Consumer端：</strong></p>
<ol>
<li><p> 采用多Consumer进程或线程同时消费</p>
</li>
<li><p> 增加fetch.min.bytes，比如1KB或更大（表示服务端积攒了1KB或以上的数据，就可以返回给Consumer）</p>
</li>
</ol>

        <h4 id="调优延时">
          <a href="#调优延时" class="heading-link"><i class="fas fa-link"></i></a><a href="#调优延时" class="headerlink" title="调优延时"></a>调优延时</h4>
      <p><strong>Broker端：</strong></p>
<p>同上适当增加num.replica.fetchers</p>
<p><strong>Producer端：</strong></p>
<ol>
<li><p> 设置linger.ms=0</p>
</li>
<li><p> 不启用压缩，compression.type=none</p>
</li>
<li><p> 设置acks=1</p>
</li>
</ol>
<p><strong>Consumer端：</strong></p>
<p>设置fetch.min.bytes=1（服务端积攒1字节数据就吐给Consumer）</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/12/01/mysql_storage_engine/">MySQL存储引擎</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-12-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-12-01</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="MySQL存储引擎">
          <a href="#MySQL存储引擎" class="heading-link"><i class="fas fa-link"></i></a><a href="#MySQL存储引擎" class="headerlink" title="MySQL存储引擎"></a>MySQL存储引擎</h3>
      
        <h4 id="Innodb（应用最广泛，现在默认的存储引擎）">
          <a href="#Innodb（应用最广泛，现在默认的存储引擎）" class="heading-link"><i class="fas fa-link"></i></a><a href="#Innodb（应用最广泛，现在默认的存储引擎）" class="headerlink" title="Innodb（应用最广泛，现在默认的存储引擎）"></a>Innodb（应用最广泛，现在默认的存储引擎）</h4>
      <p><strong>设计目的：</strong></p>
<p>用来处理大量的短期事务</p>
<p><strong>重要特点：</strong></p>
<ul>
<li><p>支持事务</p>
</li>
<li><p>支持行级锁</p>
</li>
<li><p>自动崩溃恢复</p>
</li>
<li><p>采用MVCC来支持高并发</p>
</li>
<li><p>基于聚簇索引建立</p>
</li>
<li><p>大量内部优化（可预测性预读、自适应哈希、插入缓冲区等）</p>
</li>
<li><p>支持热备份（MySQL Enterprise Backup、XtraBackup也可以）</p>
</li>
</ul>
<p><strong>重要特性：</strong></p>
<ul>
<li><p>利用排序创建索引</p>
</li>
<li><p>删除或者增加索引时不需要复制全表数据</p>
</li>
<li><p>新的支持压缩的存储格式</p>
</li>
<li><p>新的大型列值如BLOB的存储方式</p>
</li>
<li><p>文件格式管理</p>
</li>
</ul>

        <h4 id="MyISAM（5-1及之前的默认存储引擎）">
          <a href="#MyISAM（5-1及之前的默认存储引擎）" class="heading-link"><i class="fas fa-link"></i></a><a href="#MyISAM（5-1及之前的默认存储引擎）" class="headerlink" title="MyISAM（5.1及之前的默认存储引擎）"></a>MyISAM（5.1及之前的默认存储引擎）</h4>
      <p><strong>重要特点：</strong></p>
<ul>
<li><p>默认只能处理256TB（因为指针长度是6字节，最多可以修改到8字节，MAX_ROWS和AVG_ROW_LENGTH)</p>
</li>
<li><p>表存储在两个文件（.MYD存数据文件, .MYI存索引文件）</p>
</li>
</ul>
<p><strong>重要特性：</strong></p>
<ul>
<li><p>表级锁，读表共享锁，写表排他锁（但是可以通过并发插入，在读表的时候插入新记录）</p>
</li>
<li><p>支持修复（有可能会丢失数据）</p>
</li>
<li><p>全文索引（基于分词创建）</p>
</li>
<li><p>对BLOB和TEXT等长字段，可以基于前500个字符创建索引</p>
</li>
<li><p>延迟更新索引键（DELAY_KEY_WRITE，索引修改写入到内存钟的键缓冲区，键缓冲区加Mutex锁，在清理缓冲区或关闭表时写入磁盘。极大提升了性能，但有可能在异常情况下造成索引损坏）</p>
</li>
<li><p>压缩表（只读，支持索引且索引也只读。可以减少磁盘空间占用，减少磁盘IO）</p>
</li>
<li><p>空间函数（支持地理空间搜索）</p>
</li>
</ul>
<p><strong>主要缺陷：</strong></p>
<ul>
<li><p>不支持事务</p>
</li>
<li><p>不支持行级锁（并发写入的性能较低）</p>
</li>
<li><p>崩溃后无法安全恢复</p>
</li>
</ul>

        <h4 id="Archive（针对插入和压缩做了优化的简单引擎）">
          <a href="#Archive（针对插入和压缩做了优化的简单引擎）" class="heading-link"><i class="fas fa-link"></i></a><a href="#Archive（针对插入和压缩做了优化的简单引擎）" class="headerlink" title="Archive（针对插入和压缩做了优化的简单引擎）"></a>Archive（针对插入和压缩做了优化的简单引擎）</h4>
      <p><strong>重要特点：</strong></p>
<ul>
<li><p>只支持INSERT和SELECT</p>
</li>
<li><p>支持行级锁</p>
</li>
<li><p>支持专用的缓冲区</p>
</li>
<li><p>缓存所有的写并利用zlib对插入行进行压缩（磁盘I/O比MyISAM更少）</p>
</li>
</ul>
<p><strong>重要特性：</strong></p>
<ul>
<li><p>一个查询返回表中存在的所有行数前，阻止其他的SELECT执行（保证一致性读）</p>
</li>
<li><p>批量插入完成前对读操作不可见（模仿了事务机制和MVCC）</p>
</li>
</ul>
<p><strong>适用场景：</strong></p>
<ol>
<li><p>日志数据采集类应用</p>
</li>
<li><p>需要更快INSERT操作</p>
</li>
</ol>

        <h4 id="Blackhole（仅可作为特殊的复制架构和日志审核手段）（经常带来问题，不推荐使用）">
          <a href="#Blackhole（仅可作为特殊的复制架构和日志审核手段）（经常带来问题，不推荐使用）" class="heading-link"><i class="fas fa-link"></i></a><a href="#Blackhole（仅可作为特殊的复制架构和日志审核手段）（经常带来问题，不推荐使用）" class="headerlink" title="Blackhole（仅可作为特殊的复制架构和日志审核手段）（经常带来问题，不推荐使用）"></a>Blackhole（仅可作为特殊的复制架构和日志审核手段）（经常带来问题，不推荐使用）</h4>
      
        <h4 id="CSV（作为数据交换的机制）">
          <a href="#CSV（作为数据交换的机制）" class="heading-link"><i class="fas fa-link"></i></a><a href="#CSV（作为数据交换的机制）" class="headerlink" title="CSV（作为数据交换的机制）"></a>CSV（作为数据交换的机制）</h4>
      <p><strong>重要特点：</strong></p>
<ul>
<li><p>可以将CSV文件作为表（CSV作为表不支持索引）</p>
</li>
<li><p>可以在数据库运行时拷入或拷出文件</p>
</li>
</ul>
<p><strong>适用场景：</strong></p>
<ul>
<li><p>Excel等电子表格软件中的数据快速存入MySQL</p>
</li>
<li><p>外部程序需要立即从表的数据文件中读取CSV格式的数据</p>
</li>
</ul>

        <h4 id="Federated（提供跨服务器的灵活性）（经常带来问题，默认禁用）">
          <a href="#Federated（提供跨服务器的灵活性）（经常带来问题，默认禁用）" class="heading-link"><i class="fas fa-link"></i></a><a href="#Federated（提供跨服务器的灵活性）（经常带来问题，默认禁用）" class="headerlink" title="Federated（提供跨服务器的灵活性）（经常带来问题，默认禁用）"></a>Federated（提供跨服务器的灵活性）（经常带来问题，默认禁用）</h4>
      <p><strong>设计目的：</strong></p>
<p>为了和Microsoft SQL Server和Oracle竞争</p>
<p><strong>重要特点：</strong></p>
<ul>
<li><p>其他MySQL服务器的一个代理</p>
</li>
<li><p>能够建立远程MySQL连接，将查询传输到远程服务器上执行</p>
</li>
</ul>

        <h4 id="Memory（早期叫HEAP，内存数据引擎，超快访问速度）：">
          <a href="#Memory（早期叫HEAP，内存数据引擎，超快访问速度）：" class="heading-link"><i class="fas fa-link"></i></a><a href="#Memory（早期叫HEAP，内存数据引擎，超快访问速度）：" class="headerlink" title="Memory（早期叫HEAP，内存数据引擎，超快访问速度）："></a>Memory（早期叫HEAP，内存数据引擎，超快访问速度）：</h4>
      <p><strong>重要特点：</strong></p>
<ul>
<li><p>数据都存在内存中（不需要磁盘I/O，查询速度至少比MyISAM快一个数量级）</p>
</li>
<li><p>重启后会保留表结构，但数据会丢失</p>
</li>
<li><p>支持Hash索引</p>
</li>
</ul>
<p><strong>主要缺陷：</strong></p>
<ul>
<li><p>仅支持表级锁（并发写入的性能较低）</p>
</li>
<li><p>不支持BLOB或TEXT类型的列</p>
</li>
<li><p>每行的长度固定（即使指定VARCHAR，实际存储也会转换成CHAR，可能导致内存浪费）</p>
</li>
</ul>
<p><strong>适用场景：</strong></p>
<ol>
<li><p>用于查找或映射表</p>
</li>
<li><p>用于缓存周期性聚合数据的结果</p>
</li>
<li><p>用于保存数据分析中产生的中间数据</p>
</li>
<li><p>MySQL内部使用的临时表（如果MySQL查询中间结果太大超过了Memory表的限制，或包含BLOB或TEXT字段，临时表自动转换为MyISAM）</p>
</li>
</ol>

        <h4 id="Merge（用于日志或者数据仓库类应用，被MySQL分区功能完全击败，已放弃）">
          <a href="#Merge（用于日志或者数据仓库类应用，被MySQL分区功能完全击败，已放弃）" class="heading-link"><i class="fas fa-link"></i></a><a href="#Merge（用于日志或者数据仓库类应用，被MySQL分区功能完全击败，已放弃）" class="headerlink" title="Merge（用于日志或者数据仓库类应用，被MySQL分区功能完全击败，已放弃）"></a>Merge（用于日志或者数据仓库类应用，被MySQL分区功能完全击败，已放弃）</h4>
      <p><strong>重要特点：</strong></p>
<ul>
<li><p>很多特点类同MyISAM（MyISAM的变种）</p>
</li>
<li><p>多个MyISAM表合并出来的虚拟表</p>
</li>
</ul>

        <h4 id="NDB（集群引擎）">
          <a href="#NDB（集群引擎）" class="heading-link"><i class="fas fa-link"></i></a><a href="#NDB（集群引擎）" class="headerlink" title="NDB（集群引擎）"></a>NDB（集群引擎）</h4>
      <p><strong>重要特点：</strong></p>
<p>多MySQL服务器+NDB集群存储引擎+NDB数据库（保证分布式、share-nothing、容灾及高可用）=MySQL集群</p>

        <h4 id="第三方存储引擎">
          <a href="#第三方存储引擎" class="heading-link"><i class="fas fa-link"></i></a><a href="#第三方存储引擎" class="headerlink" title="第三方存储引擎"></a>第三方存储引擎</h4>
      <ul>
<li><p>OLTP类引擎（XtraDB、PBXT）</p>
</li>
<li><p>面向列的引擎（Infobright）</p>
</li>
<li><p>社区引擎（Aria、Groonga、OQGraph、Q4M、SphinxSE、Spider、VPForMySQL）</p>
</li>
</ul>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/12/01/kafka-deadlock-analysis/">kafka_deadlock_analysis</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-12-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-12-01</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="Kafka死锁问题">
          <a href="#Kafka死锁问题" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka死锁问题" class="headerlink" title="Kafka死锁问题"></a>Kafka死锁问题</h2>
      
        <h3 id="问题现象">
          <a href="#问题现象" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h3>
      <p>以数据服务团队的CUPS系统为例，upkafka-1.0版本出现的问题主要会产生如下异常现象：</p>
<ol>
<li>文件句柄增多（能够达到40w+）</li>
<li>CLOSE_WAIT增多（数量同样非常巨大）</li>
<li>单节点hang住，该节点为leader的分区，其他节点无法同步消息（从ISR中掉队），再加上外部客户端无法连上该节点，导致分区不可用，高可用失效</li>
<li>jstack抓到死锁信息，循环等待的monitor都是a kafka.coordinator.group.GroupMetadata，wait的位置都是DelayedProduce中的方法</li>
</ol>

        <h3 id="问题梳理">
          <a href="#问题梳理" class="heading-link"><i class="fas fa-link"></i></a><a href="#问题梳理" class="headerlink" title="问题梳理"></a>问题梳理</h3>
      <p>这里先解释下什么是延迟操作，它是Kafka中用来等待一些比较耗时的操作结果，会有Kafka内置的时间轮去控制延迟操作的最大等待时间。源码里面给了两个例子，生产者的延迟操作是等待足够数量的ACK(-1的情况下需要topic副本数个ACK，1的情况下只需要Leader副本的ACK)后进行校验；Fetch的延迟操作时等待足够字节的消息累积后进行校验，本质上Fetch跟消费是一样的，都是满足数量或者时间条件后返回批量的消息集合。</p>
<p>这里先截取jstack中抓到的deadlock部分信息：</p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Found one Java-level deadlock:</span><br><span class="line">=============================</span><br><span class="line">&quot;executor-Produce&quot;:</span><br><span class="line">  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-5&quot;</span><br><span class="line">&quot;kafka-request-handler-5&quot;:</span><br><span class="line">  waiting to lock monitor 0x00007fd83001aec8 (object 0x00000000bd7336c0, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-0&quot;</span><br><span class="line">&quot;kafka-request-handler-0&quot;:</span><br><span class="line">  waiting to lock monitor 0x0000000000630ab8 (object 0x00000000bda748b8, a kafka.coordinator.group.GroupMetadata),</span><br><span class="line">  which is held by &quot;kafka-request-handler-5&quot;</span><br></pre></td></tr></table></div></figure>

<p>kafka-request-handler-0和kafka-request-handler-5的堆栈如下：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;kafka-request-handler-5&quot;</span>:</span><br><span class="line">	at kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:<span class="number">75</span>)</span><br><span class="line">	- waiting to lock &lt;<span class="number">0x00000000bd7336c0</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:<span class="number">338</span>)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:<span class="number">244</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:<span class="number">250</span>)</span><br><span class="line">	at kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:<span class="number">418</span>)</span><br><span class="line">	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:<span class="number">500</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">546</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.immutable.Map$Map1.foreach(Map.scala:<span class="number">116</span>)</span><br><span class="line">	at scala.collection.TraversableLike$class.map(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.AbstractTraversable.map(Traversable.scala:<span class="number">104</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:<span class="number">373</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:<span class="number">239</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:<span class="number">381</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:<span class="number">464</span>)</span><br><span class="line">	- locked &lt;<span class="number">0x00000000bda748b8</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:<span class="number">427</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:<span class="number">356</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handle(KafkaApis.scala:<span class="number">105</span>)</span><br><span class="line">	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:<span class="number">66</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line"><span class="string">&quot;kafka-request-handler-0&quot;</span>:</span><br><span class="line">	at kafka.server.DelayedProduce.safeTryComplete(DelayedProduce.scala:<span class="number">75</span>)</span><br><span class="line">	- waiting to lock &lt;<span class="number">0x00000000bda748b8</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory$Watchers.tryCompleteWatched(DelayedOperation.scala:<span class="number">338</span>)</span><br><span class="line">	at kafka.server.DelayedOperationPurgatory.checkAndComplete(DelayedOperation.scala:<span class="number">244</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.tryCompleteDelayedProduce(ReplicaManager.scala:<span class="number">250</span>)</span><br><span class="line">	at kafka.cluster.Partition.tryCompleteDelayedRequests(Partition.scala:<span class="number">418</span>)</span><br><span class="line">	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:<span class="number">500</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">546</span>)</span><br><span class="line">	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$<span class="number">2.</span>apply(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.TraversableLike$$anonfun$map$<span class="number">1.</span>apply(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.immutable.Map$Map1.foreach(Map.scala:<span class="number">116</span>)</span><br><span class="line">	at scala.collection.TraversableLike$class.map(TraversableLike.scala:<span class="number">234</span>)</span><br><span class="line">	at scala.collection.AbstractTraversable.map(Traversable.scala:<span class="number">104</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:<span class="number">532</span>)</span><br><span class="line">	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:<span class="number">373</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.appendForGroup(GroupMetadataManager.scala:<span class="number">239</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupMetadataManager.storeOffsets(GroupMetadataManager.scala:<span class="number">381</span>)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.doCommitOffsets(GroupCoordinator.scala:<span class="number">464</span>)</span><br><span class="line">	- locked &lt;<span class="number">0x00000000bd7336c0</span>&gt; (a kafka.coordinator.group.GroupMetadata)</span><br><span class="line">	at kafka.coordinator.group.GroupCoordinator.handleCommitOffsets(GroupCoordinator.scala:<span class="number">427</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handleOffsetCommitRequest(KafkaApis.scala:<span class="number">356</span>)</span><br><span class="line">	at kafka.server.KafkaApis.handle(KafkaApis.scala:<span class="number">105</span>)</span><br><span class="line">	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:<span class="number">66</span>)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br></pre></td></tr></table></div></figure>

<p>我们在jstack文件中，发现了多个handler线程互相之间存在死锁，死锁的两次monitor都是GroupMetadata的对象。互成死锁的两条handler线程的跳转逻辑，可以参考下面这个图（整体的流程上是站在分区的维度上，先提交偏移量，后执行日志追加）：</p>
<p><img src="/2021/12/01/kafka-deadlock-analysis/kafka_deadlock_analysis.jpg" alt="kafka_deadlock_analysis"></p>
<p>社区ISSUES上，大佬给出的说法是，他们从堆栈跟踪排查到在执行正常的代码逻辑时持有了消费组的锁，并在后续的追加操作中尝试锁定同一分区的所有其他组。我们可以从源码中找到，第一次加锁的位置是在doCommitOffsets处，对传入的group(GroupMetadata类型的对象）加锁了；第二次加锁的位置就是在tryCompleteWatched里，这个方法是去尝试完成Watchers中的延迟请求。</p>
<p>Watchers是延迟操作的内置类，Watchers中维护了一个ConcurrentLinkedQueue的对象，用来存所有延迟请求。而上面的tryCompleteWatched方法就是去完成这个队列中的延迟请求。本例中，Watchers类主要涉及到的变量和方法如下：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Watchers</span>(<span class="params">val key: <span class="type">Any</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> operations = <span class="keyword">new</span> <span class="type">ConcurrentLinkedQueue</span>[<span class="type">T</span>]()</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历operations，并且尝试去完成一部分延迟请求</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tryCompleteWatched</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> completed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> iter = operations.iterator()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">      <span class="keyword">val</span> curr = iter.next()</span><br><span class="line">      <span class="keyword">if</span> (curr.isCompleted) &#123;</span><br><span class="line">        <span class="comment">// 如果其他线程已经完成了，就从operations中移除</span></span><br><span class="line">        iter.remove()</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curr.safeTryComplete()) &#123;		<span class="comment">// 死锁的问题点在这里</span></span><br><span class="line">        iter.remove()</span><br><span class="line">        completed += <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (operations.isEmpty)</span><br><span class="line">      removeKeyIfEmpty(key, <span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">    completed</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>我们的死锁问题出现在safeTryComplete()方法这里，这里实际上对group进行了二次加锁，并且由于是从Watchers中的ConcurrentLinkedQueue里遍历的，group并不一定是第一次加锁时的group（有可能是别的线程已加锁过的group，因而产生死锁）：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedProduce</span>(<span class="params">delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     produceMetadata: <span class="type">ProduceMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     lockOpt: <span class="type">Option</span>[<span class="type">Object</span>] = <span class="type">None</span></span>)                    </span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">DelayedOperation</span>(delayMs) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> lock = lockOpt.getOrElse(<span class="keyword">this</span>)</span><br><span class="line">  ...</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// lock即为传入的lockOpt，一级级传下来，实质是GroupMetadata对象</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">safeTryComplete</span></span>(): <span class="type">Boolean</span> = lock synchronized &#123;		</span><br><span class="line">    tryComplete()</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>PS：如果好奇group怎么传进来的话，往上倒退二次就可以找到lockOpt传入的源头。上一级是appendRecords里面创建了一个DelayedProduce对象，lockOpt为传入的delayedProduceLock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                  requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                  internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                  isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                  delayedProduceLock: <span class="type">Option</span>[<span class="type">Object</span>] = <span class="type">None</span>) &#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">// 创建一个DelayedProduce对象</span></span><br><span class="line"> <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>再往上倒退就可以清楚的看到，初始化appendRecords的实例的时候，把group(GroupMetadata对象)作为参数传进去了，也就是delayedProduceLock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendForGroup</span></span>(group: <span class="type">GroupMetadata</span>,</span><br><span class="line">                           records: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                           callback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// call replica manager to append the group message</span></span><br><span class="line">  replicaManager.appendRecords(</span><br><span class="line">    timeout = config.offsetCommitTimeoutMs.toLong,</span><br><span class="line">    requiredAcks = config.offsetCommitRequiredAcks,</span><br><span class="line">    internalTopicsAllowed = <span class="literal">true</span>,</span><br><span class="line">    isFromClient = <span class="literal">false</span>,</span><br><span class="line">    entriesPerPartition = records,</span><br><span class="line">    responseCallback = callback,</span><br><span class="line">    delayedProduceLock = <span class="type">Some</span>(group))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="修复方式">
          <a href="#修复方式" class="heading-link"><i class="fas fa-link"></i></a><a href="#修复方式" class="headerlink" title="修复方式"></a>修复方式</h3>
      
        <h4 id="循环等待消除">
          <a href="#循环等待消除" class="heading-link"><i class="fas fa-link"></i></a><a href="#循环等待消除" class="headerlink" title="循环等待消除"></a>循环等待消除</h4>
      <p>社区对该死锁问题的解决主要是解决第二次对其他的group(GroupMetadata对象)加锁的问题。</p>
<p>社区修复是在各延迟操作的父类DelayedOperation中内置了一个DelayedOperation私有对象的ReentrantLock，这个ReentrantLock是由DelayedOperation初始化的时候传入的Lock来决定的。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">DelayedOperation</span>(<span class="params">override val delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    lockOpt: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span></span>) <span class="keyword">extends</span> <span class="title">TimerTask</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span>[server] <span class="keyword">val</span> lock: <span class="type">Lock</span> = lockOpt.getOrElse(<span class="keyword">new</span> <span class="type">ReentrantLock</span>)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>DelayedProduce作为DelayedOperation的子类，初始化的时候也带了一个Lock：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DelayedProduce</span>(<span class="params">delayMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     produceMetadata: <span class="type">ProduceMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     replicaManager: <span class="type">ReplicaManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                     lockOpt: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">DelayedOperation</span>(delayMs, lockOpt) &#123;</span><br><span class="line">  ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>在appendForGroup这里，调用appendRecords的时候传入的也是group.lock(也是ReentrantLock)：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendForGroup</span></span>(group: <span class="type">GroupMetadata</span>,                             records: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],                             callback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;    <span class="comment">// call replica manager to append the group message    replicaManager.appendRecords(      timeout = config.offsetCommitTimeoutMs.toLong,      requiredAcks = config.offsetCommitRequiredAcks,      internalTopicsAllowed = true,      isFromClient = false,      entriesPerPartition = records,      delayedProduceLock = Some(group.lock),      responseCallback = callback)&#125;</span></span><br></pre></td></tr></table></div></figure>

<p>最后一级级流转，调用了DelayedOperation中的maybeTryComplete()，这里的lock就是来自于传入的group.lock。不同于之前强制进行第二次sychronized加锁的方式，这里进行了校验，如果获取锁失败的话，会直接退出。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[server] <span class="function"><span class="keyword">def</span> <span class="title">maybeTryComplete</span></span>(): <span class="type">Boolean</span> = &#123;    <span class="keyword">if</span> (lock.tryLock()) &#123;      <span class="keyword">try</span> &#123;        tryComplete()      &#125; <span class="keyword">finally</span> &#123;        lock.unlock()      &#125;    &#125; <span class="keyword">else</span>      <span class="literal">false</span>  &#125;</span><br></pre></td></tr></table></div></figure>

<p>通过这样的方式来解决“线程1加锁A-加锁B-退出B-退出A”， “线程2加锁B-加锁A-退出A-退出B”导致的死锁。</p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/11/30/kafka_orders/">Kafka常用命令</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-11-30</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-11-30</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h3 id="Kafka常用命令">
          <a href="#Kafka常用命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h3>
      
        <h4 id="节点命令">
          <a href="#节点命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#节点命令" class="headerlink" title="节点命令"></a>节点命令</h4>
      <ul>
<li><p>启动：bin/kafka-server-start.sh config/server.properties</p>
</li>
<li><p>停止：bin/kafka-server-stop.sh</p>
</li>
<li><p>消费者压测工具：bin/kafka-consumer-perf-test.sh –messages 100000 –message-size 500 –broker-list 172.21.36.29:9093,172.21.36.180:9092,172.21.36.30:9094 –threads 20 –num-fetch-threads 20 –batch-size 500 –consumer.config ./config/consumer.properties –topic test11</p>
</li>
<li><p>生产者压测工具：bin/kafka-producer-perf-test.sh –num-records 1000 –record-size 5 –throughput 10000 –producer-props bootstrap.servers=172.21.36.29:9093,172.21.36.180:9092,172.21.36.30:9094 –topic test</p>
</li>
<li><p>最简单版生产消息：bin/kafka-console-producer.sh -broker-list 192.168.130.128:9092 -topic test</p>
<p>  如果要发送key：bin/kafka-console-producer.sh –broker-list 192.168.130.128:9092 -topic test –property parse.key=true –property key.separator=”:”</p>
</li>
<li><p>新消费者消费消息：bin/kafka-console-consumer.sh –bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 –topic test –new-consumer –from-beginning –consumer.config config/consumer.properties</p>
<p> 如果要看key：bin/kafka-console-consumer.sh –bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 –topic test –new-consumer –from-beginning –consumer.config config/consumer.properties –property print.key=true –property key.separator=”:”</p>
</li>
</ul>

        <h4 id="Topic命令">
          <a href="#Topic命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#Topic命令" class="headerlink" title="Topic命令"></a>Topic命令</h4>
      <ul>
<li><p>新建topic：bin/kafka-topics.sh -create -zookeeper 192.168.130.128:2181 -replication-factor 2 -partitions 4 -topic test</p>
</li>
<li><p>查询指定topic的LogSize：bin/kafka-run-class.sh kafka.tools.GetOffsetShell –broker-list 192.168.130.128:9092 –topic test –time -1</p>
</li>
<li><p>分区工具三部曲：</p>
<p>bin/kafka-reassign-partitions.sh –zookeeper 192.168.130.128:2181 –topics-to-move-json-file ./bin/topics-to-move.json –broker-list “2” –generate</p>
<p>bin/kafka-reassign-partitions.sh –zookeeper 192.168.130.128:2181 –reassignment-json-file ./bin/reassignment.json –execute</p>
<p>bin/kafka-reassign-partitions.sh –zookeeper 192.168.130.128:2181 –reassignment-json-file ./bin/reassignment.json –verify</p>
</li>
</ul>

        <h4 id="消费组命令">
          <a href="#消费组命令" class="heading-link"><i class="fas fa-link"></i></a><a href="#消费组命令" class="headerlink" title="消费组命令"></a>消费组命令</h4>
      <ul>
<li><p>查询消费组消费进度（0.8）：bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker –topic test1 –zookeeper 192.168.130.128:2181 –group offset-father</p>
</li>
<li><p>查询消费组消费进度：bin/kafka-consumer-groups.sh –new-consumer –bootstrap-server 192.168.130.128:9092,192.168.130.128:9093 –group offset-father –describe</p>
</li>
<li><p>自定义设置开始偏移量：/bin/kafka-consumer-groups.sh –bootstrap-server 192.168.130.128:9092 –group offset-father –topic test1 –execute –reset-offsets –to-earliest</p>
</li>
</ul>
</div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">Yuyuyyyyyy</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">4</div><div class="sidebar-ov-state-item__name">Archives</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Yu Jie</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.4.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>